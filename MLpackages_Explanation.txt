CV2---

cv2.imread(image) -Reads the image

cv2.imshow('result',combo_image)- Displays the image

cv2.VideoCapture("test2.mp4") -Captures the video

cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) - converts the image to grayscale image

cv2.GaussianBlur(gray,(5,5),0)  - blurs the image

cv2.Canny(blur,50,150) - Darkens the image

cv2.fillPoly(mask,polygons,255) - apply the boundary 'polygons' against masked image and fill with white image 
within the mask

cv2.findChessboardCorners(image, (8,6), None) -Finding chessboard corners (for an 8x6 board)

cv2.drawChessboardCorners(img, (8,6), corners, ret) - Drawing detected corners on an image where corners and ret are response on cv2.findChessboardCorners

cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None) -Camera calibration, given object points, image points, and the shape of the grayscale image

cv2.undistort(img, mtx, dist, None, mtx) -- where img is distorted image and mtx is camera matrix  , dist is distortion coefficeint outputted from calibrate function

cv2.bitwise_and(image,mask) - performs bitwise and operation

cv2.HoughLinesP(cropped_canny, 2, np.pi/180, 100, np.array([]), minLineLength=40,maxLineGap=5) -  applies houghlines transformation
cv2.line to draw the line in a black image

cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)--draws a line with this coordinates

cv2.addWeighted(frame, 0.8, line_image, 1, 1)--  blend the line with original image

cv2.resize(img_array,(28,28) - resize the image

cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) -- changes image color to grayscale

cv2.equalizeHist(img) - Standardise the lighting in all of our images

MATPLOTIB:

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib.patches import Rectangle

original_image=mpimg.imread(image) - Reads the image

_,ax=plt.subplots(figsize=(4,4))  -- use plt.subplots to plot multiple plots on same figure
ax.scatter(top_region[:,0], top_region[:,1], color='r') --to display the scattered data and give color as r(red)
plt.pause(0.0001) --- plot pauses for 0.0001 secs
axes[0].hist(y_train, bins=num_bins,width=0.05,color='blue') -Computes and plot a histogram.
cmap=plt.get_cmap("gray") - colormapping to grayscale image
cmap=plt.get_cmap('jet')) - colormapping to jet 
axs.imshow(image,cmap=plt.get_cmap("gray"))--plot the image with grayscale
axs[j][i].set_title(str(j)) -- set title for the plot
plt.imshow(img) - plot the image
plt.bar(range(0,num_classes),num_of_samples)--displays the bar chart
plt.plot(h.history['accuracy']) - displays accuracy values from model.fit
plt.title('accuracy')- displays the title
plt.xlabel('epoch')- displays the x axis as epoch
plt.legend(['accuracy']) --creates a legend
plt.contourf(xx,yy,z) -- contour plot to produce separated label
plt.show() -show the plot

import open3d as o3d--To work with 3D data (such as lidar) that can be used in either Python or C++.

Tensorflow:

tf.convert_to_tensor(arr) - Tensors are a type of array used by Tensorflow. They have a lot in common with numpy arrays.
tf.exp(logits) -- exponentials of logits
tf.boolean_mask(scaled_logits, one_hot) -- mask the logits
tf.math.log(masked_logits) - calculates loogs of masked output
tf.Variable(x) -`tf.Variable` allow us to calculate gradients
tf.GradientTape() - calculate the gradient of a function
tf.argmax- to find the index of highest probability
tf.cast(aug_img/255.0, tf.float32) -cast tensor from one type to another
from tensorflow.keras.preprocessing import image_dataset_from_directory
dataset = image_dataset_from_directory(args.imdir, 
                                           image_size=(32, 32),
                                           validation_split=0.1,
                                           subset='training',
                                           seed=123,
                                           batch_size=1)

Keras:


model=Sequential() -- instantiates a model

model.add(Dense(units=1,input_shape=(2,), activation='sigmoid'))-- add the layer Dense

adam=Adam(lr=0.1) - optimising the learning late( gradient descent) as 0.1

model.add(Conv2D(30,[5,5],input_shape=(28,28,1),activation="relu"))- add a layer Conv2D

model.add(MaxPooling2D(pool_size=(2,2)))--add a layer MaxPooling2D

model.add(Flatten()) -- Flatten the image to 1D to feed this to Fully connected layer

model.add(Dropout(0.5))-- Reduces overfitting

model.compile(adam, loss='binary_crossentropy',metrics=['accuracy']) - compiles our model

h=model.fit(x=X,y=y,verbose=1,batch_size=50,epochs=500,shuffle='true') - execute our model

model.predict(grid) -- predicts the output

model.evaluate(X_test,y_test,verbose=0) -- evaluates the test data

model.summary - summarizes the model

y_cat=to_categorical(y,5) -- hot encodes with 5 classifications

(X_train,y_train),(X_test,y_test)=mnist.load_data -- loads mnist data

from keras.preprocessing.image import ImageDataGenerator
datagen=ImageDataGenerator(width_shift_range=0.1,
                          height_shift_range=0.1,
                          zoom_range=0.2,
                          shear_range=0.1,
                          rotation_range=10.)        -used for augmentation

datagen.fit(X_train) - fits our data to imagedatagenerator model

SCIPY: 

from scipy.stats.distributions import chi2

chi2.ppf(p, df)--ppf stands for percent point function, which is the inverse of the cumulative density function

SKLEARN:
from sklearn import datasets

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, StandardScaler, QuantileTransformer

X_train,X_valid,y_train,y_valid=train_test_split(image_paths,steerings,test_size=0.2, random_state=6) - defines test and training set
X,y=datasets.make_circles(n_samples=n_pts,random_state=123,noise=0.1,factor=0.2) -makes a circle
X,y=datasets.make_blobs(n_samples=n_pts,random_state=123,centers=centers,cluster_std=0.4)--makes a blob

Waymo dataset: 
from tools.waymo_reader.simple_waymo_open_dataset_reader import WaymoDataFileReader, dataset_pb2, label_pb2
WaymoDataFileReader(data_fullpath) - Loads the data in data_fullpath

camera_name = dataset_pb2.CameraName.FRONT --Access the data from camera sensor
image = [obj for obj in frame.images if obj.name == camera_name][0]

lidar_name = dataset_pb2.LaserName.TOP --Access the data from Lidar
lidar = [obj for obj in frame.lasers if obj.name == lidar_name][0]

lidar_calib = [obj for obj in frame.context.laser_calibrations if obj.name == lidar_name][0] -- gets laser calibration

min_pitch = lidar_calib.beam_inclination_min
max_pitch = lidar_calib.beam_inclination_max
vfov = max_pitch - min_pitch  --- The above 3 lines computes vertical field-of-view from lidar calibration by subtracting min and max inclination


Image and Image stat from PILLOW:

img.transpose(Image.FLIP_LEFT_RIGHT) - flips the image horizontally

img.resize(size) - resizes the image

img.crop((x1, y1, x2 ,y2)) - crops the image

Image.open('data/00012_00027.jpg').convert('RGB') 

Image.open(filename) - opens the image
PANDAS:

data=pd.read_csv('german-traffic-signs/signnames.csv')- reads the csv file

data.head() -displays top 5 rows

data.drop(data.index[remove_list],inplace=True) - removes the list specified 

data.iloc[i] -- pick the 'I'th row

open3D:
import open3d as o3d 

vis_lpc = o3d.visualization.VisualizerWithKeyCallback() --initialize open3d with key callback
vis_lpc.create_window(window_name='Open3D', width=1200, height=1080, left=50, top=50, visible=True) -- and create window
 pointcloud = o3d.geometry.PointCloud() --create instance of open3d point-cloud class
 pointcloud.points = o3d.utility.Vector3dVector(pcl[:,:3]) --set points in pointcloud instance by converting the point-cloud into 3d vectors (using open3d function Vector3dVector)
visualising.add_geometry(pointcloud) -- adds the pointcloud instance to visualization using add_geometry;
visualising.register_key_callback(262,right_click) - Dont close the window till right click is pressed


Aalbumentations
import albumentations as A
A.Rotate(limit=90, always_apply=True) - rotate the object 90

augmentations = A.Compose([A.Rotate(limit=90, p=1.0), 
                           A.RandomContrast(p=1.0),
                           A.CoarseDropout(p=1.0)]) -  use Compose to combine multiple augmentations.
Numpy:

np.lexsort((-lidar_pcl_cpy[:, 2], lidar_pcl_cpy[:, 1], lidar_pcl_cpy[:, 0])) -re-arrange elements in lidar_pcl_cpy by sorting first by x, then y, then -z
np.unique(lidar_pcl_cpy[:, 0:2], axis=0, return_index=True, return_counts=True) - extract all points with identical x and y such that only the top-most z-coordinate is kept 
np.pad(input_array, paddings, mode='constant', constant_values=0) - padd the input layer
np.where(lidar_pcl[:, 0] >= lim_x[0])  - retrieve the points whose coordinates are within these limits


lane_image=np.copy(image)-- Copies the image to lane_image

np.zeros_like(image)-- creates a black image with 0 pixels

np.ones(100) -- declares 100 1's'

np.average(left_fit,axis=0) -- averages the value

np.random.seed(0)--to get the same random numbers all the time

np.random.normal(10,2,n_pts) -- generate random n_pts between  10 and 2 axis with normal distribution

np.zeros(3) --Declares 3 zeroes

np.matrix([np.zeros(3)]).T -- declares a matrix and transoposes it

np.vstack((top_region, bottom_region)) - vertically stacks both the points
np.meshgrid(x_span,y_span)--create 2D grid

xx.ravel()-- use ravel to make it 1D

np.c_[xx_,yy_] -- concatenate every row with corresponding columns

np.asarray(img) -- change the image to array

np.linspace(-3,3,500) -- distributes points across coordinates

np.sin(X) - sin of X

np.histogram(data['steering'],num_bins)

np.matmul(A,B) , np.dot(A,B) and np.inner(A,b)

multiplies every row with column and adds up

np.linalg.matrix_power(a,3)
np.int_ - converts into 8 bit integer value

a to the power of 3

np.kron(A,B)

A is multiplied point by point with B and  output like 3x3 and 3x3 oututs 9x9


np.linalg.cholesky(A)

Cholesky Decomposition - transpose conjucation multiplied by itself

np.linalg.qr(A)
QR Decomposition

Q is orthogonal matrix and R is Rectangle

np.linalg.eig(A)
outputs Eigen value Decomposition(EVD)

np.linalg.eigvals(A)
outputs just value of eigens

np.diag(d)
outputs Diagonal matrix

np.linalg.inv(P)

inverse matrix of P

np.real(P)
retrieves only real part and ignores imaginary part

np.linalg.svd(A)

retrieves single value decomposition (A=USVt)

np.linalg.norm(A)

function that takes matrices as input and retrieves a single number

np.linalg.cond(A)

represents singularity

np.linalg.det(B)
represents determinant

np.linalg.matrix_rank(B)
determines the rank of matrix

np.trace(A)

sums up the diagonal elements

np.pi/4 -to denote angle 45 degree

np.arctan(pos_sens[1]/pos_sens[0]) -- it is inverse tangent function, or arcus tangens used to calc angle between object and x-axis

np.inf -infinity

np.argmin(A, axis=None)--To get the indices of the minimum entry in the association matrix A,


















